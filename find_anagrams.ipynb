{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "import torch.nn.functional as F\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('common_words_no_names.txt') as f:\n",
    "    common_words = f.read().splitlines()\n",
    "g = t.Generator().manual_seed(214743647)\n",
    "numerated = {}\n",
    "for i in range(len(common_words)):\n",
    "    numerated[common_words[i]] = i\n",
    "\n",
    "lookup = t.randn((len(common_words), 10), generator = g)\n",
    "lookup1 = lookup.clone().detach()\n",
    "common_words = set(common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2SdpaAttention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = 'gpt2'  \n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name, clean_up_tokenization_spaces = False)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prob(text):\n",
    "    if ' ' not in text:\n",
    "        return t.tensor(0)\n",
    "    input_ids = tokenizer.encode(text, return_tensors='pt')\n",
    "    prob = 1\n",
    "    with t.no_grad():\n",
    "        outputs = model(input_ids)\n",
    "        logits = outputs.logits\n",
    "    for i in range(list(t.Tensor.size(input_ids))[1] - 1):\n",
    "        next_token_logits = logits[:, i, :]\n",
    "        probabilities = F.softmax(next_token_logits, dim=-1)\n",
    "        next_token_id = input_ids[0][i + 1].item()\n",
    "        prob *= probabilities[0][next_token_id]\n",
    "    if prob != 1:\n",
    "        return prob\n",
    "    else:\n",
    "        return t.tensor(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A:\n",
    "    def __init__(self):\n",
    "        self.common_words = open('common_words_no_names.txt').read().split()\n",
    "        with open('memo_dict.json', 'r') as f:\n",
    "            self.memoDict = json.load(f)\n",
    "\n",
    "    def save_anagrams(self):\n",
    "        open('memo_dict.json', 'r').close()\n",
    "        with open('memo_dict.json', 'w') as f:\n",
    "            json.dump(self.memoDict, f)\n",
    "\n",
    "    def anagwams(self, word):\n",
    "        if word == '':\n",
    "            return ['']\n",
    "        if word in self.memoDict:\n",
    "            return self.memoDict[word]\n",
    "        dict = {}\n",
    "        for w in common_words:\n",
    "            wordHusk = word\n",
    "            included = True\n",
    "            for c in w:\n",
    "                if c not in wordHusk:\n",
    "                    included = False\n",
    "                    break\n",
    "                else:\n",
    "                    i = wordHusk.index(c)\n",
    "                    wordHusk = wordHusk[:i] + wordHusk[i+1:]\n",
    "            if included:\n",
    "                dict[w] = wordHusk\n",
    "        if len(word) < self.length - 1:\n",
    "                self.memoDict[word] = [w + ' ' + g for w in list(dict.keys()) for g in self.anagwams(dict[w])]\n",
    "        return [w + ' ' + g for w in list(dict.keys()) for g in self.anagwams(dict[w])]\n",
    "\n",
    "    def anagrams(self, input_word):\n",
    "        self.length = len(input_word)\n",
    "        input_word = input_word.lower()\n",
    "        word = ''\n",
    "        # for c in input_word:\n",
    "        #     if c in 'abcdefghijklmnopqrstuvwxyz':\n",
    "        #         word += c\n",
    "        words = self.anagwams(input_word.lower())\n",
    "        for w in words:\n",
    "            w = w.split(' ')\n",
    "        return \"\\n\".join(sorted(words, reverse = True, key = get_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing it \n",
      "setting it \n",
      "it testing \n",
      "it setting \n",
      "tin gets it \n",
      "tin get its \n",
      "tin it gets \n",
      "get tits in \n",
      "tin its get \n",
      "gets tit in \n",
      "tin get sit \n",
      "get in tits \n",
      "tn it is get \n",
      "tn is get it \n",
      "tin get ist \n",
      "in get tits \n",
      "gets in tit \n",
      "tin ist get \n",
      "tin sit get \n",
      "tn i get its \n",
      "gets tin it \n",
      "tn i gets it \n",
      "sit tin get \n",
      "sin get tit \n",
      "tn get is it \n",
      "tn get it is \n",
      "in tits get \n",
      "its tin get \n",
      "ins get tit \n",
      "tn is it get \n",
      "tn its i get \n",
      "gets it tin \n",
      "get tit ins \n",
      "sin tit get \n",
      "sit get tin \n",
      "ins tit get \n",
      "ist tin get \n",
      "tn sit i get \n",
      "titten sig \n",
      "its get tin \n",
      "tn i it gets \n",
      "get tin its \n",
      "it sig tent \n",
      "it tent sig \n",
      "ist get tin \n",
      "it gets tin \n",
      "get tit sin \n",
      "tits get in \n",
      "it tin gets \n",
      "get sin tit \n",
      "in tit gets \n",
      "it gis tent \n",
      "get tin sit \n",
      "get its tin \n",
      "get sit tin \n",
      "tn it gets i \n",
      "in gets tit \n",
      "tn it si get \n",
      "ten sig tit \n",
      "get tin ist \n",
      "tn it get is \n",
      "tn it i gets \n",
      "tn get i its \n",
      "get ins tit \n",
      "ten tit sig \n",
      "tn i get sit \n",
      "tn i get ist \n",
      "tn get its i \n",
      "tn get i sit \n",
      "tit gets in \n",
      "tn si get it \n",
      "get ist tin \n",
      "get tn it is \n",
      "tn ist i get \n",
      "net tit sig \n",
      "tn i its get \n",
      "tn gets i it \n",
      "tn its get i \n",
      "tn get it si \n",
      "tits in get \n",
      "sit i get tn \n",
      "tn get ist i \n",
      "gets i tn it \n",
      "tn gets it i \n",
      "titten gis \n",
      "gis titten \n",
      "get it is tn \n",
      "tn get si it \n",
      "tn get i ist \n",
      "sit get i tn \n",
      "tit get sin \n",
      "tn i sit get \n",
      "tit in gets \n",
      "ten gis tit \n",
      "sit i tn get \n",
      "tn get sit i \n",
      "net sig tit \n",
      "gets it i tn \n",
      "ten tit gis \n",
      "tn it get si \n",
      "get i tn its \n",
      "si it get tn \n",
      "i it gets tn \n",
      "get it si tn \n",
      "get is it tn \n",
      "is tn get it \n",
      "sig titten \n",
      "its i tn get \n",
      "gets tn i it \n",
      "gets it tn i \n",
      "net tit gis \n",
      "tn si it get \n",
      "it tent gis \n",
      "tit get ins \n",
      "its tn i get \n",
      "get it tn is \n",
      "is get it tn \n",
      "tn sit get i \n",
      "ist i get tn \n",
      "sit tn i get \n",
      "tit sig net \n",
      "get tn is it \n",
      "si get it tn \n",
      "it gets i tn \n",
      "ist get i tn \n",
      "get is tn it \n",
      "tit ins get \n",
      "tn i ist get \n",
      "is it get tn \n",
      "its i get tn \n",
      "si it tn get \n",
      "tent sig it \n",
      "its get i tn \n",
      "net gis tit \n",
      "gets tn it i \n",
      "tn ist get i \n",
      "sit get tn i \n",
      "is it tn get \n",
      "get si tn it \n",
      "ist tn i get \n",
      "get ist i tn \n",
      "it get is tn \n",
      "it get tn is \n",
      "i get tn its \n",
      "is tn it get \n",
      "tit net sig \n",
      "is get tn it \n",
      "si tn get it \n",
      "tit sig ten \n",
      "tit ten gis \n",
      "ist i tn get \n",
      "get its i tn \n",
      "get tn i sit \n",
      "get tn its i \n",
      "si tn it get \n",
      "it is get tn \n",
      "it is tn get \n",
      "gis net tit \n",
      "gets i it tn \n",
      "tit ten sig \n",
      "tit sin get \n",
      "i tn gets it \n",
      "i gets it tn \n",
      "si get tn it \n",
      "i tn get its \n",
      "i it tn gets \n",
      "get it tn si \n",
      "it tn is get \n",
      "it i tn gets \n",
      "i tn it gets \n",
      "get tn i its \n",
      "its tn get i \n",
      "get i tn sit \n",
      "sig tit ten \n",
      "sit tn get i \n",
      "get sit i tn \n",
      "get si it tn \n",
      "get tn sit i \n",
      "tent it sig \n",
      "sig tent it \n",
      "tit gis ten \n",
      "gis it tent \n",
      "i tn its get \n",
      "gis ten tit \n",
      "get tn it si \n",
      "i get its tn \n",
      "tent gis it \n",
      "gis tit ten \n",
      "i get tn sit \n",
      "sig ten tit \n",
      "it i gets tn \n",
      "it tn get is \n",
      "ist tn get i \n",
      "tit net gis \n",
      "sig net tit \n",
      "sig tit net \n",
      "i get tn ist \n",
      "i its get tn \n",
      "tit gis net \n",
      "get i tn ist \n",
      "ist get tn i \n",
      "it tn i gets \n",
      "it get tn si \n",
      "its get tn i \n",
      "it get si tn \n",
      "gis tent it \n",
      "i gets tn it \n",
      "get tn i ist \n",
      "it tn si get \n",
      "get tn si it \n",
      "i tn sit get \n",
      "get its tn i \n",
      "it gets tn i \n",
      "gis tit net \n",
      "i tn get sit \n",
      "get ist tn i \n",
      "tent it gis \n",
      "i tn get ist \n",
      "sig it tent \n",
      "it tn get si \n",
      "it si get tn \n",
      "i its tn get \n",
      "get i sit tn \n",
      "get sit tn i \n",
      "get tn ist i \n",
      "i sit tn get \n",
      "get i its tn \n",
      "it si tn get \n",
      "i tn ist get \n",
      "it tn gets i \n",
      "i get sit tn \n",
      "i sit get tn \n",
      "get i ist tn \n",
      "i get ist tn \n",
      "i ist get tn \n",
      "i ist tn get \n"
     ]
    }
   ],
   "source": [
    "g = A()\n",
    "print(g.anagrams('testingit')) # initial: 13.1; after: 12.6, 11.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Before the towers\"\n",
    "input_ids = tokenizer.encode(text, return_tensors='pt')\n",
    "with t.no_grad():\n",
    "    outputs = model(input_ids)\n",
    "    logits = outputs.logits\n",
    "\n",
    "# Get logits for the last token in the input sequence\n",
    "next_token_logits = logits[:, -1, :]\n",
    "\n",
    "# Convert logits to probabilities\n",
    "probabilities = F.softmax(next_token_logits, dim=-1)\n",
    "\n",
    "# Get the top 10 most probable tokens\n",
    "top_k = 10\n",
    "top_k_probs, top_k_indices = t.topk(probabilities, top_k)\n",
    "\n",
    "top_k_tokens = tokenizer.decode(top_k_indices[0]).split()\n",
    "top_k_probabilities = top_k_probs[0].tolist()\n",
    "\n",
    "for token, prob in zip(top_k_tokens, top_k_probabilities):\n",
    "    i = 0\n",
    "    #print(f\"Token: {token}, Probability: {prob:.4f}\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
